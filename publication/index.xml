<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Publications | Yuxing Wang</title>
    <link>https://Yuxing-Wang-THU.github.io/publication/</link>
      <atom:link href="https://Yuxing-Wang-THU.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Publications</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© 2023 Yuxing Wang</copyright><lastBuildDate>Sat, 01 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://Yuxing-Wang-THU.github.io/media/icon_hu03acb205fb0b40f635b48bbdfaf3118f_242332_512x512_fill_lanczos_center_3.png</url>
      <title>Publications</title>
      <link>https://Yuxing-Wang-THU.github.io/publication/</link>
    </image>
    
    <item>
      <title>Curriculum-based Co-design of Morphology and Control of Voxel-based Soft Robots</title>
      <link>https://Yuxing-Wang-THU.github.io/publication/cuco/</link>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/publication/cuco/</guid>
      <description>&lt;p style=&#34;text-align:justify&#34;;&gt;The philosophy of embodied cognition inspires the domain of robotics that a robot&#39;s ability to interact with the environment depends both on its brain (control policy) and body (morphology), which are inherently coupled. However, finding an optimal robot morphology and its controller for solving a given task is often unfeasible. The major challenge for this endeavor is the enormous combined design and policy space. Firstly, the freedom to pick the number of multi-material modules and the ways they are connected makes it notoriously difficult to explore the design space. For instance, in a robot simulator, there are over $4\times10^{8}$ possible morphologies for a robot composed of only 12 modules. Secondly, the evaluation of a morphology requires a separate training procedure for its unique controller.&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;In this work, we consider the co-optimization of design and control of Voxel-based Soft Robots (VSRs), a form of modular soft robots composed of elastic, multi-material cubic blocks. Unlike fragile fully-integrated robots, they can be easily disassembled and reassembled to adapt to a wide range of environments. For efficiently exploring the modular robot design space, prior approaches commonly rely on artificial evolution, which maintains a population of design prototypes and adopts a bi-level optimization loop, where the outer loop of morphology optimization is based on the fitness of individual controllers from the inner loop. These methods, however, tend to learn from scratch in the target design space where there is a significant combinatorial explosion. Thus, they spend a large amount of time on policy optimization and evaluation. Additionally, their separate training procedures significantly hinder the experience of design and control to be shared across different robots.&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;In view of these challenges, we propose a Curriculum-based Co-design (CuCo) method for learning to design and control VSRs from easy to difficult. CuCo draws inspiration from Curriculum Learning (CL) that starting with easier tasks can help the agent learn better when presented with more difficult tasks later on. The key to our approach is expanding the design space from a small size to the target size gradually through a predefined curriculum. Precisely, at each stage of the curriculum, we learn practical design and control patterns via Reinforcement Learning (RL), which is enabled by incorporating the design process into the environment and using differentiable policy representations. The converged morphology and the learned policies from last stage are inherited and then serve as the starting point for the next stage. Due to the exploitation of the previous knowledge of design and control, CuCo can quickly produce robust morphologies with better performance in larger dimensional settings.&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt; Visualization of converged morphologies of all methods in the Pusher environment across three different runs. Below each VSR is its average performance.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./CuCo2.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt; Visualization of CuCo’s learning process in UpStepper and Pusher. The x-axis represents the number of policy iterations and the y-axis represents the curriculum. We show morphologies in the stage from left to right.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;./CuCo3.png&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;More visual results are shown in the following video.&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/video.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
</description>
    </item>
    
    <item>
      <title>Dynamics-Adaptive Continual Reinforcement Learning via Progressive Contextualization</title>
      <link>https://Yuxing-Wang-THU.github.io/publication/dacorl/</link>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/publication/dacorl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Surrogate-Assisted Controller for Expensive Evolutionary Reinforcement Learning</title>
      <link>https://Yuxing-Wang-THU.github.io/publication/serl/</link>
      <pubDate>Sat, 04 Dec 2021 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/publication/serl/</guid>
      <description>&lt;p style=&#34;text-align:justify&#34;;&gt;A HalfCheetah agent trained by SPDERL-I with average performance of 14000 points over 50 test seeds. The agent is able to adjust its posture more appropriately and run faster.&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/2.HalfCheetah_trained_by_SPDERL-I_14000.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;A Hopper agent trained by SPDERL-I with average performance of 4100 points over 50 test seeds. The agent jumps faster and learns to better stabilize the center of gravity.&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/3.Hopper_trained_by_SPDERL-I_4100.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
&lt;p style=&#34;text-align:justify&#34;;&gt;A Walker agent trained by SPDERL-G with average performance of 9000 points over 50 test seeds. The agent learns to walk with only one leg and use the other leg to maintain balance.&lt;/p&gt;









  





&lt;video controls  &gt;
  &lt;source src=&#34;https://Yuxing-Wang-THU.github.io/media/6.Walker_trained_by_SPDERL-G_9000.mp4&#34; type=&#34;video/mp4&#34;&gt;
&lt;/video&gt;
</description>
    </item>
    
    <item>
      <title>From Big Data Based Price Discrimination to Privacy Leakage: Ethical Analysis and Reflections on Privacy Issues from the Perspective of Hardware and Software</title>
      <link>https://Yuxing-Wang-THU.github.io/publication/dataethics/</link>
      <pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://Yuxing-Wang-THU.github.io/publication/dataethics/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
